{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_restoration_using_GAN_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anspire/Notebooks/blob/master/Image_restoration_using_GAN_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMpDZAyLCaBx",
        "colab_type": "text"
      },
      "source": [
        "# Image Restoration using GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOkF16FRmuC2",
        "colab_type": "text"
      },
      "source": [
        "**Image Restoration** is the operation of taking a corrupt/noisy image and estimating the clean, original image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "insnPyAeRC0x",
        "colab_type": "text"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoYMgagKCFdn",
        "colab_type": "text"
      },
      "source": [
        "## Intended Structure after Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCHJeTjnhj05",
        "colab_type": "text"
      },
      "source": [
        "Run the blocks in this section to get the following directory structure:\n",
        "```\n",
        "/content\n",
        "│\n",
        "└───rephrase-pubfig831\n",
        "    │\n",
        "    └───correct\n",
        "    │   │\n",
        "    │   └───train\n",
        "    │   │   │\n",
        "    │   │   └───Adam Sandler\n",
        "    │   │   │   │   train__000001-000000.jpg\n",
        "    │   │   │   │   train__000001-000001.jpg\n",
        "    │   │   │   │   train__000001-000002.jpg\n",
        "    │   │   │   │   ...\n",
        "    │   │   │\n",
        "    │   │   └───Alec Baldwin\n",
        "    │   │   │   │   train__000002-000000.jpg\n",
        "    │   │   │   │   train__000002-000001.jpg\n",
        "    │   │   │   │   ...\n",
        "    │   │   │\n",
        "    │   │   └───Angelina Jolie\n",
        "    │   │   │   │   train__000003-000000.jpg\n",
        "    │   │   │   │   train__000003-000001.jpg\n",
        "    │   │   │   │   ...\n",
        "    │   │   │\n",
        "    │   │   │ ...\n",
        "    │   │\n",
        "    │   └───test\n",
        "    │       │\n",
        "    │       └───Adam Sandler\n",
        "    │       │   │   test__000001-000000.jpg\n",
        "    │       │   │   test__000001-000001.jpg\n",
        "    │       │   │   ...\n",
        "    │       │\n",
        "    │       └───Alec Baldwin\n",
        "    │       │   │   test__000002-000000.jpg\n",
        "    │       │   │   ...\n",
        "    │       │\n",
        "    │       └───Angelina Jolie\n",
        "    │       │   │   test__000003-000000.jpg\n",
        "    │       │   │   ...\n",
        "    │       │\n",
        "    │       │ ...\n",
        "    │\n",
        "    │\n",
        "    └───degraded\n",
        "        │   <Same directory structure as 'correct'>\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58tM3kFPNZ0Z",
        "colab_type": "text"
      },
      "source": [
        "Every image in the degraded directory is a degraded version of the image with the same name in the correct directory. e.g. `/content/rephrase-pubfig831/degraded/Adam Sandler/train__000001-000002.jpg` is the degraded version of `/content/rephrase-pubfig831/correct/Adam Sandler/train__000001-000002.jpg`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUrGJB04RF4d",
        "colab_type": "text"
      },
      "source": [
        "## Installation (pip etc)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3ljp1DHRNt7",
        "colab_type": "code",
        "outputId": "1eb382ba-d1f4-4cc4-8aff-f67d85b48929",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "!pip install GPUtil\n",
        "!pip install tqdm\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting GPUtil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7410 sha256=bc200f48ef9485d84897fb0de1f2b51485f18609093e0e789c7f1db510508a5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil\n",
            "Successfully installed GPUtil-1.4.0\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNJbKsnjR74d",
        "colab_type": "text"
      },
      "source": [
        "## Downloading and Generating Dataset\n",
        "Run this block only once. Do not modify it. Also, don't call the degrade function in your code anywhere. You should treat the degradation process as a black box."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozoy8Olklwaj",
        "colab_type": "code",
        "outputId": "f77764c0-65a9-4705-c1d1-14db98695580",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "import os\n",
        "from glob import glob\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def degrade(path: str) -> None:\n",
        "    \"\"\"Load image at `input_path`, distort and save as `output_path`\"\"\"\n",
        "    SHIFT = 2\n",
        "    image = cv2.imread(path)\n",
        "    to_swap = np.random.choice([False, True], image.shape[:2], p=[.8, .2])\n",
        "    swap_indices = np.where(to_swap[:-SHIFT] & ~to_swap[SHIFT:])\n",
        "    swap_vals = image[swap_indices[0] + SHIFT, swap_indices[1]]\n",
        "    image[swap_indices[0] + SHIFT, swap_indices[1]] = image[swap_indices]\n",
        "    image[swap_indices] = swap_vals\n",
        "    cv2.imwrite(path, image)\n",
        "\n",
        "!wget http://briancbecker.com/files/downloads/pubfig83lfw/pubfig83lfw_raw_in_dirs.zip\n",
        "!unzip -q pubfig83lfw_raw_in_dirs.zip\n",
        "!rm pubfig83lfw_raw_in_dirs.zip\n",
        "!mkdir rephrase-pubfig831\n",
        "!mv pubfig83lfw_raw_in_dirs rephrase-pubfig831/correct\n",
        "!rm -r rephrase-pubfig831/correct/distract\n",
        "!cp -r rephrase-pubfig831/correct rephrase-pubfig831/degraded\n",
        "\n",
        "for image_path in tqdm(glob('rephrase-pubfig831/degraded/*/*/*.jpg')):\n",
        "  degrade(image_path)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-06 21:56:04--  http://briancbecker.com/files/downloads/pubfig83lfw/pubfig83lfw_raw_in_dirs.zip\n",
            "Resolving briancbecker.com (briancbecker.com)... 162.241.216.158\n",
            "Connecting to briancbecker.com (briancbecker.com)|162.241.216.158|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 400247922 (382M) [application/zip]\n",
            "Saving to: ‘pubfig83lfw_raw_in_dirs.zip’\n",
            "\n",
            "pubfig83lfw_raw_in_ 100%[===================>] 381.71M  25.4MB/s    in 16s     \n",
            "\n",
            "2019-11-06 21:56:20 (23.8 MB/s) - ‘pubfig83lfw_raw_in_dirs.zip’ saved [400247922/400247922]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 13002/13002 [01:03<00:00, 205.79it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kz5BM22VralE",
        "colab_type": "text"
      },
      "source": [
        "# **Checking Free Memory**\n",
        "This block is just so that you can have an idea of the resources you have at hand on the Google Collab system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoMS9HMX6G9D",
        "colab_type": "code",
        "outputId": "c3698dbb-ba57-4878-d1b9-cccdc280f706",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "gpu = GPU.getGPUs()[0]\n",
        "process = psutil.Process(os.getpid())\n",
        "print(f\"Gen RAM: Free {humanize.naturalsize(psutil.virtual_memory().available)} | Proc size {humanize.naturalsize(process.memory_info().rss)}\")\n",
        "print(f\"GPU RAM: Free {gpu.memoryFree:.0f}MB | Used {gpu.memoryUsed:.0f}MB | Util {gpu.memoryUtil*100:.0f}% | Total {gpu.memoryTotal:.0f}MB\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM: Free 26.4 GB | Proc size 176.1 MB\n",
            "GPU RAM: Free 11441MB | Used 0MB | Util 0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMubMpKy15ac",
        "colab_type": "text"
      },
      "source": [
        "# **Main Code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLV1XdpqWNOz",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00YEMKLdWH_Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "4c44f0f3-44e0-4cd8-ea87-17bef5974c01"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from os.path import isfile, join, exists\n",
        "\n",
        "import keras.backend as K\n",
        "from keras.optimizers import Adam\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import BatchNormalization, Activation\n",
        "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, add\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose, UpSampling2D"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqLOT8BUsAaW",
        "colab_type": "text"
      },
      "source": [
        "## Constants and Hyperparemeters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8NNBxqO4qPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_path = 'rephrase-pubfig831'\n",
        "model_path = '/content'\n",
        "image_shape = (256,256,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIuewxbgsM4d",
        "colab_type": "text"
      },
      "source": [
        "## Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4DoUU8GYJes",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(path, image_shape, train = True):\n",
        "  path = join(path, 'degraded')\n",
        "  if train:\n",
        "    path = join(path, 'train')\n",
        "  else:\n",
        "    path = join(path, 'test')\n",
        "  dirs = os.listdir(path)\n",
        "  fpaths = []\n",
        "  for root, dirs, files in os.walk(path):\n",
        "    for file in files:\n",
        "      fpaths.append(join(root, file))\n",
        "  X = []\n",
        "  Y = []\n",
        "  w, h, _ = image_shape\n",
        "  for f_name in fpaths:\n",
        "    x = cv2.imread(f_name)\n",
        "    y = cv2.imread(f_name.replace('degraded', 'correct'))\n",
        "\n",
        "    x = cv2.resize(x, (w, h), interpolation=cv2.INTER_LINEAR)\n",
        "    y = cv2.resize(y, (w, h), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    X.append(x)\n",
        "    Y.append(y)\n",
        "  \n",
        "  X = (np.asarray(X).astype(np.float32) - 127.5)/127.5 \n",
        "  Y = (np.asarray(Y).astype(np.float32) - 127.5)/127.5 \n",
        "  \n",
        "  return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8d1iCkzrtcG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4535d7ac-045d-40bd-eaed-c8fcc5e104cf"
      },
      "source": [
        "X_train, Y_train = load_data(dataset_path, image_shape, train = True)\n",
        "print('Number of Training examples :', X_train.shape[0])\n",
        "\n",
        "#X_test, Y_test = load_data(dataset_path, image_shape, train = False)\n",
        "#print('Number of Training examples :', X_test.shape[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Training examples : 8720\n",
            "Number of Training examples : 4282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boM1O6VU4BtD",
        "colab_type": "text"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQr7M263s-CE",
        "colab_type": "text"
      },
      "source": [
        "### Generator Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLjLc0INPJY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(object):\n",
        "  \n",
        "  def __init__(self, input_shape):\n",
        "    self.input_shape = input_shape\n",
        "\n",
        "  def res_block(self, x, kernal_size, filters, strides):\n",
        "    gen = x\n",
        "    \n",
        "    x = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(x)\n",
        "    x = BatchNormalization(momentum = 0.5)(x)\n",
        "    x = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(x)\n",
        "    x = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(x)\n",
        "    x = BatchNormalization(momentum = 0.5)(x)\n",
        "    \n",
        "    return add([gen, x])\n",
        "\n",
        "  def generator(self):\n",
        "    gen_input = Input(shape = self.input_shape)\n",
        "    x = Conv2D(filters = 64, kernel_size = 9, strides = 1, padding = \"same\")(gen_input)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    gen = x\n",
        "\n",
        "    for index in range(8):\n",
        "\t    x = self.res_block(x, 3, 64, 1)\n",
        "\n",
        "    x = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(x)\n",
        "    x = BatchNormalization(momentum = 0.5)(x)\n",
        "    x = add([gen, x])\n",
        "\t\n",
        "    x = Conv2DTranspose(filters = 32, kernel_size = 3, strides = 1, padding = \"same\")(x)\n",
        "    x = LeakyReLU(alpha = 0.2)(x)\n",
        "    x = Conv2DTranspose(filters = 16, kernel_size = 3, strides = 1, padding = \"same\")(x)\n",
        "    x = LeakyReLU(alpha = 0.2)(x)\n",
        "    x = Conv2D(filters = 3, kernel_size = 9, strides = 1, padding = \"same\")(x)\n",
        "    x = Activation('tanh')(x)\n",
        "\t   \n",
        "    return Model(inputs = gen_input, outputs = x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzGcCAE0nS-y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8f769b2f-b3f8-40fb-d32c-b8dff63cb5bc"
      },
      "source": [
        "generator = Generator(image_shape).generator()\n",
        "generator.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 256, 256, 64) 15616       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 256, 256, 64) 0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 256, 256, 64) 36928       leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 256, 256, 64) 256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_1 (PReLU)               (None, 256, 256, 64) 64          batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 256, 256, 64) 36928       p_re_lu_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 256, 256, 64) 256         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 256, 256, 64) 0           leaky_re_lu_1[0][0]              \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 256, 256, 64) 36928       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 256, 256, 64) 256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_2 (PReLU)               (None, 256, 256, 64) 64          batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 256, 256, 64) 36928       p_re_lu_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 256, 256, 64) 256         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 256, 256, 64) 0           add_1[0][0]                      \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 256, 256, 64) 36928       add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 256, 256, 64) 256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_3 (PReLU)               (None, 256, 256, 64) 64          batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 256, 256, 64) 36928       p_re_lu_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 256, 256, 64) 256         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 256, 256, 64) 0           add_2[0][0]                      \n",
            "                                                                 batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 256, 256, 64) 36928       add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 256, 256, 64) 256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_4 (PReLU)               (None, 256, 256, 64) 64          batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 256, 256, 64) 36928       p_re_lu_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 256, 256, 64) 256         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 256, 256, 64) 0           add_3[0][0]                      \n",
            "                                                                 batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 256, 256, 64) 36928       add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 256, 256, 64) 256         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_5 (PReLU)               (None, 256, 256, 64) 64          batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 256, 256, 64) 36928       p_re_lu_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 256, 256, 64) 256         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 256, 256, 64) 0           add_4[0][0]                      \n",
            "                                                                 batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 256, 256, 64) 36928       add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 256, 256, 64) 256         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_6 (PReLU)               (None, 256, 256, 64) 64          batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 256, 256, 64) 36928       p_re_lu_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 256, 256, 64) 256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 256, 256, 64) 0           add_5[0][0]                      \n",
            "                                                                 batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 256, 256, 64) 36928       add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 256, 256, 64) 256         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_7 (PReLU)               (None, 256, 256, 64) 64          batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 256, 256, 64) 36928       p_re_lu_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 256, 256, 64) 256         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 256, 256, 64) 0           add_6[0][0]                      \n",
            "                                                                 batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 256, 256, 64) 36928       add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 256, 256, 64) 256         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_8 (PReLU)               (None, 256, 256, 64) 64          batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 256, 256, 64) 36928       p_re_lu_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 256, 256, 64) 256         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 256, 256, 64) 0           add_7[0][0]                      \n",
            "                                                                 batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 256, 256, 64) 36928       add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 256, 256, 64) 256         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 256, 256, 64) 0           leaky_re_lu_1[0][0]              \n",
            "                                                                 batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 256, 256, 32) 18464       add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 256, 256, 32) 0           conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 256, 256, 16) 4624        leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 256, 256, 16) 0           conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 256, 256, 3)  3891        leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 256, 256, 3)  0           conv2d_19[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 675,235\n",
            "Trainable params: 673,059\n",
            "Non-trainable params: 2,176\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u7Eq3yltYld",
        "colab_type": "text"
      },
      "source": [
        "### Discriminator Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ6tsJqgi-Gd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(object):\n",
        "\n",
        "  def __init__(self, input_shape):\n",
        "    self.input_shape = input_shape\n",
        "\n",
        "  def discriminator_block(self, x, filters, kernel_size, strides):\n",
        "    x = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = \"same\")(x)\n",
        "    x = BatchNormalization(momentum = 0.5)(x)\n",
        "    x = LeakyReLU(alpha = 0.2)(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "  def discriminator(self):\n",
        "    dis_input = Input(shape = self.input_shape)\n",
        "    x = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(dis_input)\n",
        "    x = LeakyReLU(alpha = 0.2)(x)\n",
        "    \n",
        "    x = self.discriminator_block(x, 64, 3, 2)\n",
        "    x = self.discriminator_block(x, 128, 3, 1)\n",
        "    x = self.discriminator_block(x, 128, 3, 2)\n",
        "    x = self.discriminator_block(x, 256, 3, 1)\n",
        "    x = self.discriminator_block(x, 256, 3, 2)\n",
        "    x = self.discriminator_block(x, 512, 3, 1)\n",
        "    x = self.discriminator_block(x, 512, 3, 2)\n",
        "    \n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1024)(x)\n",
        "    x = LeakyReLU(alpha = 0.2)(x)\n",
        "    x = Dense(1)(x)\n",
        "    x = Activation('sigmoid')(x) \n",
        "    \n",
        "    return Model(inputs = dis_input, outputs = x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2lkS-ZspvAL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d9040adf-e631-480b-e175-697138ae9b2f"
      },
      "source": [
        "discriminator = Discriminator(image_shape).discriminator()\n",
        "discriminator.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 256, 256, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 256, 256, 64)      1792      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 256, 256, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 128, 128, 64)      36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 128, 128, 64)      256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 128, 128, 128)     73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 128, 128, 128)     512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 128, 128, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 64, 64, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 64, 64, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 64, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 64, 64, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 64, 64, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 32, 32, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 32, 32, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 32, 32, 512)       2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 32, 32, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 16, 16, 512)       2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)   (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 131072)            0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              134218752 \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)   (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 1025      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 138,912,577\n",
            "Trainable params: 138,908,865\n",
            "Non-trainable params: 3,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vHqFRWbDxIDW"
      },
      "source": [
        "### GAN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KkfsNxvoxIDn",
        "colab": {}
      },
      "source": [
        "class GAN(object):\n",
        "\n",
        "  def __init__(self, input_shape, generator, discriminator):\n",
        "    self.input_shape = input_shape\n",
        "    self.generator = generator\n",
        "    self.discriminator = discriminator\n",
        "\n",
        "  def gan(self):\n",
        "    self.discriminator.trainable = False\n",
        "    \n",
        "    gan_input = Input(shape= self.input_shape)\n",
        "    generator_out = self.generator(gan_input)\n",
        "    discriminator_out = self.discriminator(generator_out)\n",
        "\n",
        "    return Model(inputs = gan_input, outputs = [generator_out, discriminator_out])  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r2Hwhl-ZxID_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "fb8daa93-08de-4f6e-c1ac-8d647144666c"
      },
      "source": [
        "gan = GAN(image_shape, generator, discriminator).gan()\n",
        "gan.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 256, 256, 3)       0         \n",
            "_________________________________________________________________\n",
            "model_1 (Model)              (None, 256, 256, 3)       675235    \n",
            "_________________________________________________________________\n",
            "model_2 (Model)              (None, 1)                 138912577 \n",
            "=================================================================\n",
            "Total params: 139,587,812\n",
            "Trainable params: 673,059\n",
            "Non-trainable params: 138,914,753\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bVjtttv0fKhp"
      },
      "source": [
        "## Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD0xLY_FfRRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vgg_loss(y_true, y_pred):\n",
        "  vgg19 = VGG19(include_top=False, weights='imagenet', input_shape=image_shape)\n",
        "  vgg19.trainable = False\n",
        "  for l in vgg19.layers:\n",
        "    l.trainable = False\n",
        "  loss_model = Model(inputs=vgg19.input, outputs=vgg19.get_layer('block5_conv4').output)\n",
        "  loss_model.trainable = False\n",
        "  \n",
        "  return K.mean(K.square(loss_model(y_true) - loss_model(y_pred)))\n",
        "\n",
        "loss = vgg_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OHWHhltZfP2r"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhL1Myvmopcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7msb0gPuC2A",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6Ccj64AtlK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(X_train, Y_train, generator, discriminator, gan, epochs= 5, batch_size= 16):\n",
        "  batch_count = int(X_train.shape[0] / batch_size)\n",
        "\n",
        "  #valid = np.ones((batch_size, 1))\n",
        "  #fake = np.zeros((batch_size, 1))\n",
        "\n",
        "  for e in range(1, epochs+1):\n",
        "    print ('-'*15, 'Epoch %d' % e, '-'*15)\n",
        "    d_loss = 0\n",
        "    g_loss = 0\n",
        "    for _ in range(batch_count): \n",
        "      idx = np.random.randint(0, X_train.shape[0], batch_size)  \n",
        "      x = X_train[idx]\n",
        "      y = Y_train[idx]\n",
        "\n",
        "      generated_images = generator.predict(x)\n",
        "\n",
        "      valid = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2\n",
        "      fake = np.random.random_sample(batch_size)*0.2\n",
        "\n",
        "      discriminator.trainable = True  \n",
        "      d_loss_real = discriminator.train_on_batch(y, valid)\n",
        "      d_loss_fake = discriminator.train_on_batch(generated_images, fake)\n",
        "      d_loss += 0.5 * np.add(d_loss_fake, d_loss_real)\n",
        "\n",
        "      idx = np.random.randint(0, X_train.shape[0], batch_size)  \n",
        "      x = X_train[idx]\n",
        "      y = Y_train[idx]\n",
        "\n",
        "      valid = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2\n",
        "\n",
        "      discriminator.trainable = False\n",
        "      loss = gan.train_on_batch(x,[y, valid])\n",
        "      g_loss += loss[0]\n",
        "            \n",
        "    print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (e, d_loss[0]/batch_count, 100*(d_loss[1]/batch_count), g_loss/batch_count))\n",
        "    plot_generated_images(generator, num = 5)\n",
        "    if e % 5 == 0:\n",
        "      generator.save_weights(join(model_path, 'gen_weigths.h5'))\n",
        "      discriminator.save_weights(join(model_path, 'dis_weigths.h5'))\n",
        "      gan.save_weights(join(model_path, 'gan_weigths.h5'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N5_yxU5lGad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## compile Generator\n",
        "generator.compile(loss= vgg_loss, optimizer= optimizer)\n",
        "\n",
        "## compile Discriminator\n",
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer= optimizer, metrics= ['accuracy'])\n",
        "\n",
        "## compile GAN \n",
        "gan.compile(loss=[ vgg_loss, \"binary_crossentropy\"], loss_weights=[1., 1e-3], optimizer=optimizer)\n",
        "\n",
        "## Load weigths\n",
        "if exists(join(model_path, 'gen_weigths.h5')):\n",
        "  generator.load_weights(join(model_path, 'gen_weigths.h5'))\n",
        "if exists(join(model_path, 'dis_weigths.h5')):\n",
        "  discriminator.load_weights(join(model_path, 'dis_weigths.h5'))\n",
        "if exists(join(model_path, 'gan_weigths.h5')):\n",
        "  combined.load_weights(join(model_path, 'gan_weigths.h5'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSfB0OnvnINR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "ed090fb5-b32a-4547-beba-4b156fd57be2"
      },
      "source": [
        "## Train\n",
        "train(X_train, Y_train, generator, discriminator, gan, epochs= 5, batch_size= 4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------- Epoch 1 ---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNhozLkv7N13",
        "colab_type": "text"
      },
      "source": [
        "## Save Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWDlz-sr7UUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator.save(join(model_path, 'generator_model.h5'))\n",
        "discriminator.save(join(model_path, 'discriminator_model.h5'))\n",
        "gan.save(join(model_path, 'gan_model.h5'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EloW4JAcyYDJ",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNnCAsPZgyqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_generated_images(generator, num = 5):\n",
        "  files = glob('/content/rephrase-pubfig831/correct/test/*/*')\n",
        "  grid = []\n",
        "\n",
        "  for path in random.sample(files):\n",
        "    correct = cv2.imread(path)\n",
        "    split = path.split('/')\n",
        "\n",
        "    degraded = cv2.imread('/'.join([*split[:3], 'degraded', *split[4:]]))\n",
        "    degraded = cv2.resize(degraded,(image_shape[0],image_shape[1]),interpolation=cv2.INTER_LINEAR)\n",
        "    degraded = np.expand_dims(degraded, axis=0)\n",
        "    degraded = (degraded.astype(np.float32) - 127.5)/127.5 \n",
        "\n",
        "    gen_img = generator.predict(degraded)\n",
        "\n",
        "    gen_img = (gen_img + 1) * 127.5\n",
        "    gen_img = cv2.resize(gen_img[0].astype(np.uint8) ,(250,250),interpolation=cv2.INTER_AREA)\n",
        "    grid.append(np.column_stack([degraded, gen_img, correct]))\n",
        "\n",
        "  image = np.row_stack(grid)\n",
        "  dpi = float(plt.rcParams['figure.dpi'])\n",
        "  figsize = image.shape[1] / dpi, image.shape[0] / dpi\n",
        "  ax = plt.figure(figsize=figsize).add_axes([0, 0, 1, 1])\n",
        "  ax.axis('off')\n",
        "  ax.imshow(image[..., ::-1])\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIdPxmI6kj4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_generated_images(generator)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
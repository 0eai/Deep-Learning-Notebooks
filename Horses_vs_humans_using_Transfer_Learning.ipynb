{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Horses vs. humans using Transfer Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anspire/Notebooks/blob/master/Horses_vs_humans_using_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "95b6afd5-4b55-4f0a-c507-0c01868760f3"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = 'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-27 02:52:34--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.188.128, 2404:6800:4008:c00::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.188.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "\r          inception   0%[                    ]       0  --.-KB/s               \r         inception_  30%[=====>              ]  25.29M   126MB/s               \r        inception_v  90%[=================>  ]  75.60M   189MB/s               \rinception_v3_weight 100%[===================>]  83.84M   194MB/s    in 0.4s    \n",
            "\n",
            "2019-09-27 02:52:35 (194 MB/s) - ‘inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 74, 74, 32)   864         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 74, 74, 32)   96          conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 74, 74, 32)   0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_189 (Conv2D)             (None, 72, 72, 32)   9216        activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 72, 72, 32)   96          conv2d_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 72, 72, 32)   0           batch_normalization_189[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_190 (Conv2D)             (None, 72, 72, 64)   18432       activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 72, 72, 64)   192         conv2d_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 72, 72, 64)   0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_191 (Conv2D)             (None, 35, 35, 80)   5120        max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 35, 35, 80)   240         conv2d_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 35, 35, 80)   0           batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 33, 33, 192)  138240      activation_191[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 33, 33, 192)  576         conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 33, 33, 192)  0           batch_normalization_192[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_196 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_196 (BatchN (None, 16, 16, 64)   192         conv2d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_196 (Activation)     (None, 16, 16, 64)   0           batch_normalization_196[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_197 (Conv2D)             (None, 16, 16, 96)   55296       activation_196[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 16, 16, 48)   144         conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_197 (BatchN (None, 16, 16, 96)   288         conv2d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 16, 16, 48)   0           batch_normalization_194[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_197 (Activation)     (None, 16, 16, 96)   0           batch_normalization_197[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_18 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 16, 16, 64)   76800       activation_194[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_198 (Conv2D)             (None, 16, 16, 96)   82944       activation_197[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_199 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_18[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 16, 16, 64)   192         conv2d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 16, 16, 64)   192         conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_198 (BatchN (None, 16, 16, 96)   288         conv2d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_199 (BatchN (None, 16, 16, 32)   96          conv2d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 16, 16, 64)   0           batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 16, 16, 64)   0           batch_normalization_195[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_198 (Activation)     (None, 16, 16, 96)   0           batch_normalization_198[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_199 (Activation)     (None, 16, 16, 32)   0           batch_normalization_199[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_193[0][0]             \n",
            "                                                                 activation_195[0][0]             \n",
            "                                                                 activation_198[0][0]             \n",
            "                                                                 activation_199[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_203 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_203 (BatchN (None, 16, 16, 64)   192         conv2d_203[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_203 (Activation)     (None, 16, 16, 64)   0           batch_normalization_203[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_201 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_204 (Conv2D)             (None, 16, 16, 96)   55296       activation_203[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_201 (BatchN (None, 16, 16, 48)   144         conv2d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_204 (BatchN (None, 16, 16, 96)   288         conv2d_204[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_201 (Activation)     (None, 16, 16, 48)   0           batch_normalization_201[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_204 (Activation)     (None, 16, 16, 96)   0           batch_normalization_204[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_19 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_200 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_202 (Conv2D)             (None, 16, 16, 64)   76800       activation_201[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_205 (Conv2D)             (None, 16, 16, 96)   82944       activation_204[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_206 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_19[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_200 (BatchN (None, 16, 16, 64)   192         conv2d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_202 (BatchN (None, 16, 16, 64)   192         conv2d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_205 (BatchN (None, 16, 16, 96)   288         conv2d_205[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_206 (BatchN (None, 16, 16, 64)   192         conv2d_206[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_200 (Activation)     (None, 16, 16, 64)   0           batch_normalization_200[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_202 (Activation)     (None, 16, 16, 64)   0           batch_normalization_202[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_205 (Activation)     (None, 16, 16, 96)   0           batch_normalization_205[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_206 (Activation)     (None, 16, 16, 64)   0           batch_normalization_206[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_200[0][0]             \n",
            "                                                                 activation_202[0][0]             \n",
            "                                                                 activation_205[0][0]             \n",
            "                                                                 activation_206[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_210 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_210 (BatchN (None, 16, 16, 64)   192         conv2d_210[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_210 (Activation)     (None, 16, 16, 64)   0           batch_normalization_210[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_208 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_211 (Conv2D)             (None, 16, 16, 96)   55296       activation_210[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_208 (BatchN (None, 16, 16, 48)   144         conv2d_208[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_211 (BatchN (None, 16, 16, 96)   288         conv2d_211[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_208 (Activation)     (None, 16, 16, 48)   0           batch_normalization_208[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_211 (Activation)     (None, 16, 16, 96)   0           batch_normalization_211[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_20 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_207 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_209 (Conv2D)             (None, 16, 16, 64)   76800       activation_208[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_212 (Conv2D)             (None, 16, 16, 96)   82944       activation_211[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_213 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_20[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_207 (BatchN (None, 16, 16, 64)   192         conv2d_207[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_209 (BatchN (None, 16, 16, 64)   192         conv2d_209[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_212 (BatchN (None, 16, 16, 96)   288         conv2d_212[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_213 (BatchN (None, 16, 16, 64)   192         conv2d_213[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_207 (Activation)     (None, 16, 16, 64)   0           batch_normalization_207[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_209 (Activation)     (None, 16, 16, 64)   0           batch_normalization_209[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_212 (Activation)     (None, 16, 16, 96)   0           batch_normalization_212[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_213 (Activation)     (None, 16, 16, 64)   0           batch_normalization_213[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_207[0][0]             \n",
            "                                                                 activation_209[0][0]             \n",
            "                                                                 activation_212[0][0]             \n",
            "                                                                 activation_213[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_215 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_215 (BatchN (None, 16, 16, 64)   192         conv2d_215[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_215 (Activation)     (None, 16, 16, 64)   0           batch_normalization_215[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_216 (Conv2D)             (None, 16, 16, 96)   55296       activation_215[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_216 (BatchN (None, 16, 16, 96)   288         conv2d_216[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_216 (Activation)     (None, 16, 16, 96)   0           batch_normalization_216[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_214 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_217 (Conv2D)             (None, 7, 7, 96)     82944       activation_216[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_214 (BatchN (None, 7, 7, 384)    1152        conv2d_214[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_217 (BatchN (None, 7, 7, 96)     288         conv2d_217[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_214 (Activation)     (None, 7, 7, 384)    0           batch_normalization_214[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_217 (Activation)     (None, 7, 7, 96)     0           batch_normalization_217[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_214[0][0]             \n",
            "                                                                 activation_217[0][0]             \n",
            "                                                                 max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_222 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_222 (BatchN (None, 7, 7, 128)    384         conv2d_222[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_222 (Activation)     (None, 7, 7, 128)    0           batch_normalization_222[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_223 (Conv2D)             (None, 7, 7, 128)    114688      activation_222[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_223 (BatchN (None, 7, 7, 128)    384         conv2d_223[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_223 (Activation)     (None, 7, 7, 128)    0           batch_normalization_223[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_219 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_224 (Conv2D)             (None, 7, 7, 128)    114688      activation_223[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_219 (BatchN (None, 7, 7, 128)    384         conv2d_219[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_224 (BatchN (None, 7, 7, 128)    384         conv2d_224[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_219 (Activation)     (None, 7, 7, 128)    0           batch_normalization_219[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_224 (Activation)     (None, 7, 7, 128)    0           batch_normalization_224[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_220 (Conv2D)             (None, 7, 7, 128)    114688      activation_219[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_225 (Conv2D)             (None, 7, 7, 128)    114688      activation_224[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_220 (BatchN (None, 7, 7, 128)    384         conv2d_220[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_225 (BatchN (None, 7, 7, 128)    384         conv2d_225[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_220 (Activation)     (None, 7, 7, 128)    0           batch_normalization_220[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_225 (Activation)     (None, 7, 7, 128)    0           batch_normalization_225[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_21 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_218 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_221 (Conv2D)             (None, 7, 7, 192)    172032      activation_220[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_226 (Conv2D)             (None, 7, 7, 192)    172032      activation_225[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_227 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_21[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_218 (BatchN (None, 7, 7, 192)    576         conv2d_218[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_221 (BatchN (None, 7, 7, 192)    576         conv2d_221[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_226 (BatchN (None, 7, 7, 192)    576         conv2d_226[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_227 (BatchN (None, 7, 7, 192)    576         conv2d_227[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_218 (Activation)     (None, 7, 7, 192)    0           batch_normalization_218[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_221 (Activation)     (None, 7, 7, 192)    0           batch_normalization_221[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_226 (Activation)     (None, 7, 7, 192)    0           batch_normalization_226[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_227 (Activation)     (None, 7, 7, 192)    0           batch_normalization_227[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_218[0][0]             \n",
            "                                                                 activation_221[0][0]             \n",
            "                                                                 activation_226[0][0]             \n",
            "                                                                 activation_227[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_232 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_232 (BatchN (None, 7, 7, 160)    480         conv2d_232[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_232 (Activation)     (None, 7, 7, 160)    0           batch_normalization_232[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_233 (Conv2D)             (None, 7, 7, 160)    179200      activation_232[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_233 (BatchN (None, 7, 7, 160)    480         conv2d_233[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_233 (Activation)     (None, 7, 7, 160)    0           batch_normalization_233[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_229 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_234 (Conv2D)             (None, 7, 7, 160)    179200      activation_233[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_229 (BatchN (None, 7, 7, 160)    480         conv2d_229[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_234 (BatchN (None, 7, 7, 160)    480         conv2d_234[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_229 (Activation)     (None, 7, 7, 160)    0           batch_normalization_229[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_234 (Activation)     (None, 7, 7, 160)    0           batch_normalization_234[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_230 (Conv2D)             (None, 7, 7, 160)    179200      activation_229[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_235 (Conv2D)             (None, 7, 7, 160)    179200      activation_234[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_230 (BatchN (None, 7, 7, 160)    480         conv2d_230[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_235 (BatchN (None, 7, 7, 160)    480         conv2d_235[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_230 (Activation)     (None, 7, 7, 160)    0           batch_normalization_230[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_235 (Activation)     (None, 7, 7, 160)    0           batch_normalization_235[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_22 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_228 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_231 (Conv2D)             (None, 7, 7, 192)    215040      activation_230[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_236 (Conv2D)             (None, 7, 7, 192)    215040      activation_235[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_237 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_22[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_228 (BatchN (None, 7, 7, 192)    576         conv2d_228[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_231 (BatchN (None, 7, 7, 192)    576         conv2d_231[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_236 (BatchN (None, 7, 7, 192)    576         conv2d_236[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_237 (BatchN (None, 7, 7, 192)    576         conv2d_237[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_228 (Activation)     (None, 7, 7, 192)    0           batch_normalization_228[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_231 (Activation)     (None, 7, 7, 192)    0           batch_normalization_231[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_236 (Activation)     (None, 7, 7, 192)    0           batch_normalization_236[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_237 (Activation)     (None, 7, 7, 192)    0           batch_normalization_237[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_228[0][0]             \n",
            "                                                                 activation_231[0][0]             \n",
            "                                                                 activation_236[0][0]             \n",
            "                                                                 activation_237[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_242 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_242 (BatchN (None, 7, 7, 160)    480         conv2d_242[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_242 (Activation)     (None, 7, 7, 160)    0           batch_normalization_242[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_243 (Conv2D)             (None, 7, 7, 160)    179200      activation_242[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_243 (BatchN (None, 7, 7, 160)    480         conv2d_243[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_243 (Activation)     (None, 7, 7, 160)    0           batch_normalization_243[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_239 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_244 (Conv2D)             (None, 7, 7, 160)    179200      activation_243[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_239 (BatchN (None, 7, 7, 160)    480         conv2d_239[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_244 (BatchN (None, 7, 7, 160)    480         conv2d_244[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_239 (Activation)     (None, 7, 7, 160)    0           batch_normalization_239[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_244 (Activation)     (None, 7, 7, 160)    0           batch_normalization_244[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_240 (Conv2D)             (None, 7, 7, 160)    179200      activation_239[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_245 (Conv2D)             (None, 7, 7, 160)    179200      activation_244[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_240 (BatchN (None, 7, 7, 160)    480         conv2d_240[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_245 (BatchN (None, 7, 7, 160)    480         conv2d_245[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_240 (Activation)     (None, 7, 7, 160)    0           batch_normalization_240[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_245 (Activation)     (None, 7, 7, 160)    0           batch_normalization_245[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_23 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_238 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_241 (Conv2D)             (None, 7, 7, 192)    215040      activation_240[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_246 (Conv2D)             (None, 7, 7, 192)    215040      activation_245[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_247 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_23[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_238 (BatchN (None, 7, 7, 192)    576         conv2d_238[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_241 (BatchN (None, 7, 7, 192)    576         conv2d_241[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_246 (BatchN (None, 7, 7, 192)    576         conv2d_246[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_247 (BatchN (None, 7, 7, 192)    576         conv2d_247[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_238 (Activation)     (None, 7, 7, 192)    0           batch_normalization_238[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_241 (Activation)     (None, 7, 7, 192)    0           batch_normalization_241[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_246 (Activation)     (None, 7, 7, 192)    0           batch_normalization_246[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_247 (Activation)     (None, 7, 7, 192)    0           batch_normalization_247[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_238[0][0]             \n",
            "                                                                 activation_241[0][0]             \n",
            "                                                                 activation_246[0][0]             \n",
            "                                                                 activation_247[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_252 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_252 (BatchN (None, 7, 7, 192)    576         conv2d_252[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_252 (Activation)     (None, 7, 7, 192)    0           batch_normalization_252[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_253 (Conv2D)             (None, 7, 7, 192)    258048      activation_252[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_253 (BatchN (None, 7, 7, 192)    576         conv2d_253[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_253 (Activation)     (None, 7, 7, 192)    0           batch_normalization_253[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_249 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_254 (Conv2D)             (None, 7, 7, 192)    258048      activation_253[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_249 (BatchN (None, 7, 7, 192)    576         conv2d_249[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_254 (BatchN (None, 7, 7, 192)    576         conv2d_254[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_249 (Activation)     (None, 7, 7, 192)    0           batch_normalization_249[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_254 (Activation)     (None, 7, 7, 192)    0           batch_normalization_254[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_250 (Conv2D)             (None, 7, 7, 192)    258048      activation_249[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_255 (Conv2D)             (None, 7, 7, 192)    258048      activation_254[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_250 (BatchN (None, 7, 7, 192)    576         conv2d_250[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_255 (BatchN (None, 7, 7, 192)    576         conv2d_255[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_250 (Activation)     (None, 7, 7, 192)    0           batch_normalization_250[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_255 (Activation)     (None, 7, 7, 192)    0           batch_normalization_255[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_24 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_248 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_251 (Conv2D)             (None, 7, 7, 192)    258048      activation_250[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_256 (Conv2D)             (None, 7, 7, 192)    258048      activation_255[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_257 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_24[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_248 (BatchN (None, 7, 7, 192)    576         conv2d_248[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_251 (BatchN (None, 7, 7, 192)    576         conv2d_251[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_256 (BatchN (None, 7, 7, 192)    576         conv2d_256[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_257 (BatchN (None, 7, 7, 192)    576         conv2d_257[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_248 (Activation)     (None, 7, 7, 192)    0           batch_normalization_248[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_251 (Activation)     (None, 7, 7, 192)    0           batch_normalization_251[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_256 (Activation)     (None, 7, 7, 192)    0           batch_normalization_256[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_257 (Activation)     (None, 7, 7, 192)    0           batch_normalization_257[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
            "                                                                 activation_251[0][0]             \n",
            "                                                                 activation_256[0][0]             \n",
            "                                                                 activation_257[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_260 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_260 (BatchN (None, 7, 7, 192)    576         conv2d_260[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_260 (Activation)     (None, 7, 7, 192)    0           batch_normalization_260[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_261 (Conv2D)             (None, 7, 7, 192)    258048      activation_260[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_261 (BatchN (None, 7, 7, 192)    576         conv2d_261[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_261 (Activation)     (None, 7, 7, 192)    0           batch_normalization_261[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_258 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_262 (Conv2D)             (None, 7, 7, 192)    258048      activation_261[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_258 (BatchN (None, 7, 7, 192)    576         conv2d_258[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_262 (BatchN (None, 7, 7, 192)    576         conv2d_262[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_258 (Activation)     (None, 7, 7, 192)    0           batch_normalization_258[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_262 (Activation)     (None, 7, 7, 192)    0           batch_normalization_262[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_259 (Conv2D)             (None, 3, 3, 320)    552960      activation_258[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_263 (Conv2D)             (None, 3, 3, 192)    331776      activation_262[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_259 (BatchN (None, 3, 3, 320)    960         conv2d_259[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_263 (BatchN (None, 3, 3, 192)    576         conv2d_263[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_259 (Activation)     (None, 3, 3, 320)    0           batch_normalization_259[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_263 (Activation)     (None, 3, 3, 192)    0           batch_normalization_263[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_259[0][0]             \n",
            "                                                                 activation_263[0][0]             \n",
            "                                                                 max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_268 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_268 (BatchN (None, 3, 3, 448)    1344        conv2d_268[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_268 (Activation)     (None, 3, 3, 448)    0           batch_normalization_268[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_265 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_269 (Conv2D)             (None, 3, 3, 384)    1548288     activation_268[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_265 (BatchN (None, 3, 3, 384)    1152        conv2d_265[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_269 (BatchN (None, 3, 3, 384)    1152        conv2d_269[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_265 (Activation)     (None, 3, 3, 384)    0           batch_normalization_265[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_269 (Activation)     (None, 3, 3, 384)    0           batch_normalization_269[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_266 (Conv2D)             (None, 3, 3, 384)    442368      activation_265[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_267 (Conv2D)             (None, 3, 3, 384)    442368      activation_265[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_270 (Conv2D)             (None, 3, 3, 384)    442368      activation_269[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_271 (Conv2D)             (None, 3, 3, 384)    442368      activation_269[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_25 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_264 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_266 (BatchN (None, 3, 3, 384)    1152        conv2d_266[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_267 (BatchN (None, 3, 3, 384)    1152        conv2d_267[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_270 (BatchN (None, 3, 3, 384)    1152        conv2d_270[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_271 (BatchN (None, 3, 3, 384)    1152        conv2d_271[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_272 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_25[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_264 (BatchN (None, 3, 3, 320)    960         conv2d_264[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_266 (Activation)     (None, 3, 3, 384)    0           batch_normalization_266[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_267 (Activation)     (None, 3, 3, 384)    0           batch_normalization_267[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_270 (Activation)     (None, 3, 3, 384)    0           batch_normalization_270[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_271 (Activation)     (None, 3, 3, 384)    0           batch_normalization_271[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_272 (BatchN (None, 3, 3, 192)    576         conv2d_272[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_264 (Activation)     (None, 3, 3, 320)    0           batch_normalization_264[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_266[0][0]             \n",
            "                                                                 activation_267[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 3, 3, 768)    0           activation_270[0][0]             \n",
            "                                                                 activation_271[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_272 (Activation)     (None, 3, 3, 192)    0           batch_normalization_272[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_264[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_4[0][0]              \n",
            "                                                                 activation_272[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_277 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_277 (BatchN (None, 3, 3, 448)    1344        conv2d_277[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_277 (Activation)     (None, 3, 3, 448)    0           batch_normalization_277[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_274 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_278 (Conv2D)             (None, 3, 3, 384)    1548288     activation_277[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_274 (BatchN (None, 3, 3, 384)    1152        conv2d_274[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_278 (BatchN (None, 3, 3, 384)    1152        conv2d_278[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_274 (Activation)     (None, 3, 3, 384)    0           batch_normalization_274[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_278 (Activation)     (None, 3, 3, 384)    0           batch_normalization_278[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_275 (Conv2D)             (None, 3, 3, 384)    442368      activation_274[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_276 (Conv2D)             (None, 3, 3, 384)    442368      activation_274[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_279 (Conv2D)             (None, 3, 3, 384)    442368      activation_278[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_280 (Conv2D)             (None, 3, 3, 384)    442368      activation_278[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_26 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_273 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_275 (BatchN (None, 3, 3, 384)    1152        conv2d_275[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_276 (BatchN (None, 3, 3, 384)    1152        conv2d_276[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_279 (BatchN (None, 3, 3, 384)    1152        conv2d_279[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_280 (BatchN (None, 3, 3, 384)    1152        conv2d_280[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_281 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_26[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_273 (BatchN (None, 3, 3, 320)    960         conv2d_273[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_275 (Activation)     (None, 3, 3, 384)    0           batch_normalization_275[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_276 (Activation)     (None, 3, 3, 384)    0           batch_normalization_276[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_279 (Activation)     (None, 3, 3, 384)    0           batch_normalization_279[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_280 (Activation)     (None, 3, 3, 384)    0           batch_normalization_280[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_281 (BatchN (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_273[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
            "                                                                 activation_276[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
            "                                                                 activation_280[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_281[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_5[0][0]              \n",
            "                                                                 activation_281[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "outputId": "b5169aab-9650-4e5d-8990-ac49cd14134d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('last layer output shape: ', (None, 7, 7, 768))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "47f81b1a-e278-488b-8af1-87ce449f5cca"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 74, 74, 32)   864         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 74, 74, 32)   96          conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 74, 74, 32)   0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_189 (Conv2D)             (None, 72, 72, 32)   9216        activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 72, 72, 32)   96          conv2d_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 72, 72, 32)   0           batch_normalization_189[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_190 (Conv2D)             (None, 72, 72, 64)   18432       activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 72, 72, 64)   192         conv2d_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 72, 72, 64)   0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_191 (Conv2D)             (None, 35, 35, 80)   5120        max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 35, 35, 80)   240         conv2d_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 35, 35, 80)   0           batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 33, 33, 192)  138240      activation_191[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 33, 33, 192)  576         conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 33, 33, 192)  0           batch_normalization_192[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_196 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_196 (BatchN (None, 16, 16, 64)   192         conv2d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_196 (Activation)     (None, 16, 16, 64)   0           batch_normalization_196[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_197 (Conv2D)             (None, 16, 16, 96)   55296       activation_196[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 16, 16, 48)   144         conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_197 (BatchN (None, 16, 16, 96)   288         conv2d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 16, 16, 48)   0           batch_normalization_194[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_197 (Activation)     (None, 16, 16, 96)   0           batch_normalization_197[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_18 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 16, 16, 64)   76800       activation_194[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_198 (Conv2D)             (None, 16, 16, 96)   82944       activation_197[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_199 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_18[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 16, 16, 64)   192         conv2d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 16, 16, 64)   192         conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_198 (BatchN (None, 16, 16, 96)   288         conv2d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_199 (BatchN (None, 16, 16, 32)   96          conv2d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 16, 16, 64)   0           batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 16, 16, 64)   0           batch_normalization_195[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_198 (Activation)     (None, 16, 16, 96)   0           batch_normalization_198[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_199 (Activation)     (None, 16, 16, 32)   0           batch_normalization_199[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_193[0][0]             \n",
            "                                                                 activation_195[0][0]             \n",
            "                                                                 activation_198[0][0]             \n",
            "                                                                 activation_199[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_203 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_203 (BatchN (None, 16, 16, 64)   192         conv2d_203[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_203 (Activation)     (None, 16, 16, 64)   0           batch_normalization_203[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_201 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_204 (Conv2D)             (None, 16, 16, 96)   55296       activation_203[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_201 (BatchN (None, 16, 16, 48)   144         conv2d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_204 (BatchN (None, 16, 16, 96)   288         conv2d_204[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_201 (Activation)     (None, 16, 16, 48)   0           batch_normalization_201[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_204 (Activation)     (None, 16, 16, 96)   0           batch_normalization_204[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_19 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_200 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_202 (Conv2D)             (None, 16, 16, 64)   76800       activation_201[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_205 (Conv2D)             (None, 16, 16, 96)   82944       activation_204[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_206 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_19[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_200 (BatchN (None, 16, 16, 64)   192         conv2d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_202 (BatchN (None, 16, 16, 64)   192         conv2d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_205 (BatchN (None, 16, 16, 96)   288         conv2d_205[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_206 (BatchN (None, 16, 16, 64)   192         conv2d_206[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_200 (Activation)     (None, 16, 16, 64)   0           batch_normalization_200[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_202 (Activation)     (None, 16, 16, 64)   0           batch_normalization_202[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_205 (Activation)     (None, 16, 16, 96)   0           batch_normalization_205[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_206 (Activation)     (None, 16, 16, 64)   0           batch_normalization_206[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_200[0][0]             \n",
            "                                                                 activation_202[0][0]             \n",
            "                                                                 activation_205[0][0]             \n",
            "                                                                 activation_206[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_210 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_210 (BatchN (None, 16, 16, 64)   192         conv2d_210[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_210 (Activation)     (None, 16, 16, 64)   0           batch_normalization_210[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_208 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_211 (Conv2D)             (None, 16, 16, 96)   55296       activation_210[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_208 (BatchN (None, 16, 16, 48)   144         conv2d_208[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_211 (BatchN (None, 16, 16, 96)   288         conv2d_211[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_208 (Activation)     (None, 16, 16, 48)   0           batch_normalization_208[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_211 (Activation)     (None, 16, 16, 96)   0           batch_normalization_211[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_20 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_207 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_209 (Conv2D)             (None, 16, 16, 64)   76800       activation_208[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_212 (Conv2D)             (None, 16, 16, 96)   82944       activation_211[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_213 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_20[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_207 (BatchN (None, 16, 16, 64)   192         conv2d_207[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_209 (BatchN (None, 16, 16, 64)   192         conv2d_209[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_212 (BatchN (None, 16, 16, 96)   288         conv2d_212[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_213 (BatchN (None, 16, 16, 64)   192         conv2d_213[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_207 (Activation)     (None, 16, 16, 64)   0           batch_normalization_207[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_209 (Activation)     (None, 16, 16, 64)   0           batch_normalization_209[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_212 (Activation)     (None, 16, 16, 96)   0           batch_normalization_212[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_213 (Activation)     (None, 16, 16, 64)   0           batch_normalization_213[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_207[0][0]             \n",
            "                                                                 activation_209[0][0]             \n",
            "                                                                 activation_212[0][0]             \n",
            "                                                                 activation_213[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_215 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_215 (BatchN (None, 16, 16, 64)   192         conv2d_215[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_215 (Activation)     (None, 16, 16, 64)   0           batch_normalization_215[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_216 (Conv2D)             (None, 16, 16, 96)   55296       activation_215[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_216 (BatchN (None, 16, 16, 96)   288         conv2d_216[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_216 (Activation)     (None, 16, 16, 96)   0           batch_normalization_216[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_214 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_217 (Conv2D)             (None, 7, 7, 96)     82944       activation_216[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_214 (BatchN (None, 7, 7, 384)    1152        conv2d_214[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_217 (BatchN (None, 7, 7, 96)     288         conv2d_217[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_214 (Activation)     (None, 7, 7, 384)    0           batch_normalization_214[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_217 (Activation)     (None, 7, 7, 96)     0           batch_normalization_217[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_214[0][0]             \n",
            "                                                                 activation_217[0][0]             \n",
            "                                                                 max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_222 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_222 (BatchN (None, 7, 7, 128)    384         conv2d_222[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_222 (Activation)     (None, 7, 7, 128)    0           batch_normalization_222[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_223 (Conv2D)             (None, 7, 7, 128)    114688      activation_222[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_223 (BatchN (None, 7, 7, 128)    384         conv2d_223[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_223 (Activation)     (None, 7, 7, 128)    0           batch_normalization_223[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_219 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_224 (Conv2D)             (None, 7, 7, 128)    114688      activation_223[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_219 (BatchN (None, 7, 7, 128)    384         conv2d_219[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_224 (BatchN (None, 7, 7, 128)    384         conv2d_224[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_219 (Activation)     (None, 7, 7, 128)    0           batch_normalization_219[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_224 (Activation)     (None, 7, 7, 128)    0           batch_normalization_224[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_220 (Conv2D)             (None, 7, 7, 128)    114688      activation_219[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_225 (Conv2D)             (None, 7, 7, 128)    114688      activation_224[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_220 (BatchN (None, 7, 7, 128)    384         conv2d_220[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_225 (BatchN (None, 7, 7, 128)    384         conv2d_225[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_220 (Activation)     (None, 7, 7, 128)    0           batch_normalization_220[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_225 (Activation)     (None, 7, 7, 128)    0           batch_normalization_225[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_21 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_218 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_221 (Conv2D)             (None, 7, 7, 192)    172032      activation_220[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_226 (Conv2D)             (None, 7, 7, 192)    172032      activation_225[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_227 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_21[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_218 (BatchN (None, 7, 7, 192)    576         conv2d_218[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_221 (BatchN (None, 7, 7, 192)    576         conv2d_221[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_226 (BatchN (None, 7, 7, 192)    576         conv2d_226[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_227 (BatchN (None, 7, 7, 192)    576         conv2d_227[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_218 (Activation)     (None, 7, 7, 192)    0           batch_normalization_218[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_221 (Activation)     (None, 7, 7, 192)    0           batch_normalization_221[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_226 (Activation)     (None, 7, 7, 192)    0           batch_normalization_226[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_227 (Activation)     (None, 7, 7, 192)    0           batch_normalization_227[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_218[0][0]             \n",
            "                                                                 activation_221[0][0]             \n",
            "                                                                 activation_226[0][0]             \n",
            "                                                                 activation_227[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_232 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_232 (BatchN (None, 7, 7, 160)    480         conv2d_232[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_232 (Activation)     (None, 7, 7, 160)    0           batch_normalization_232[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_233 (Conv2D)             (None, 7, 7, 160)    179200      activation_232[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_233 (BatchN (None, 7, 7, 160)    480         conv2d_233[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_233 (Activation)     (None, 7, 7, 160)    0           batch_normalization_233[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_229 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_234 (Conv2D)             (None, 7, 7, 160)    179200      activation_233[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_229 (BatchN (None, 7, 7, 160)    480         conv2d_229[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_234 (BatchN (None, 7, 7, 160)    480         conv2d_234[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_229 (Activation)     (None, 7, 7, 160)    0           batch_normalization_229[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_234 (Activation)     (None, 7, 7, 160)    0           batch_normalization_234[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_230 (Conv2D)             (None, 7, 7, 160)    179200      activation_229[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_235 (Conv2D)             (None, 7, 7, 160)    179200      activation_234[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_230 (BatchN (None, 7, 7, 160)    480         conv2d_230[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_235 (BatchN (None, 7, 7, 160)    480         conv2d_235[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_230 (Activation)     (None, 7, 7, 160)    0           batch_normalization_230[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_235 (Activation)     (None, 7, 7, 160)    0           batch_normalization_235[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_22 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_228 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_231 (Conv2D)             (None, 7, 7, 192)    215040      activation_230[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_236 (Conv2D)             (None, 7, 7, 192)    215040      activation_235[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_237 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_22[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_228 (BatchN (None, 7, 7, 192)    576         conv2d_228[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_231 (BatchN (None, 7, 7, 192)    576         conv2d_231[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_236 (BatchN (None, 7, 7, 192)    576         conv2d_236[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_237 (BatchN (None, 7, 7, 192)    576         conv2d_237[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_228 (Activation)     (None, 7, 7, 192)    0           batch_normalization_228[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_231 (Activation)     (None, 7, 7, 192)    0           batch_normalization_231[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_236 (Activation)     (None, 7, 7, 192)    0           batch_normalization_236[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_237 (Activation)     (None, 7, 7, 192)    0           batch_normalization_237[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_228[0][0]             \n",
            "                                                                 activation_231[0][0]             \n",
            "                                                                 activation_236[0][0]             \n",
            "                                                                 activation_237[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_242 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_242 (BatchN (None, 7, 7, 160)    480         conv2d_242[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_242 (Activation)     (None, 7, 7, 160)    0           batch_normalization_242[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_243 (Conv2D)             (None, 7, 7, 160)    179200      activation_242[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_243 (BatchN (None, 7, 7, 160)    480         conv2d_243[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_243 (Activation)     (None, 7, 7, 160)    0           batch_normalization_243[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_239 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_244 (Conv2D)             (None, 7, 7, 160)    179200      activation_243[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_239 (BatchN (None, 7, 7, 160)    480         conv2d_239[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_244 (BatchN (None, 7, 7, 160)    480         conv2d_244[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_239 (Activation)     (None, 7, 7, 160)    0           batch_normalization_239[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_244 (Activation)     (None, 7, 7, 160)    0           batch_normalization_244[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_240 (Conv2D)             (None, 7, 7, 160)    179200      activation_239[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_245 (Conv2D)             (None, 7, 7, 160)    179200      activation_244[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_240 (BatchN (None, 7, 7, 160)    480         conv2d_240[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_245 (BatchN (None, 7, 7, 160)    480         conv2d_245[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_240 (Activation)     (None, 7, 7, 160)    0           batch_normalization_240[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_245 (Activation)     (None, 7, 7, 160)    0           batch_normalization_245[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_23 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_238 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_241 (Conv2D)             (None, 7, 7, 192)    215040      activation_240[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_246 (Conv2D)             (None, 7, 7, 192)    215040      activation_245[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_247 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_23[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_238 (BatchN (None, 7, 7, 192)    576         conv2d_238[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_241 (BatchN (None, 7, 7, 192)    576         conv2d_241[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_246 (BatchN (None, 7, 7, 192)    576         conv2d_246[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_247 (BatchN (None, 7, 7, 192)    576         conv2d_247[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_238 (Activation)     (None, 7, 7, 192)    0           batch_normalization_238[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_241 (Activation)     (None, 7, 7, 192)    0           batch_normalization_241[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_246 (Activation)     (None, 7, 7, 192)    0           batch_normalization_246[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_247 (Activation)     (None, 7, 7, 192)    0           batch_normalization_247[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_238[0][0]             \n",
            "                                                                 activation_241[0][0]             \n",
            "                                                                 activation_246[0][0]             \n",
            "                                                                 activation_247[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_252 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_252 (BatchN (None, 7, 7, 192)    576         conv2d_252[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_252 (Activation)     (None, 7, 7, 192)    0           batch_normalization_252[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_253 (Conv2D)             (None, 7, 7, 192)    258048      activation_252[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_253 (BatchN (None, 7, 7, 192)    576         conv2d_253[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_253 (Activation)     (None, 7, 7, 192)    0           batch_normalization_253[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_249 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_254 (Conv2D)             (None, 7, 7, 192)    258048      activation_253[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_249 (BatchN (None, 7, 7, 192)    576         conv2d_249[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_254 (BatchN (None, 7, 7, 192)    576         conv2d_254[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_249 (Activation)     (None, 7, 7, 192)    0           batch_normalization_249[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_254 (Activation)     (None, 7, 7, 192)    0           batch_normalization_254[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_250 (Conv2D)             (None, 7, 7, 192)    258048      activation_249[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_255 (Conv2D)             (None, 7, 7, 192)    258048      activation_254[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_250 (BatchN (None, 7, 7, 192)    576         conv2d_250[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_255 (BatchN (None, 7, 7, 192)    576         conv2d_255[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_250 (Activation)     (None, 7, 7, 192)    0           batch_normalization_250[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_255 (Activation)     (None, 7, 7, 192)    0           batch_normalization_255[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_24 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_248 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_251 (Conv2D)             (None, 7, 7, 192)    258048      activation_250[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_256 (Conv2D)             (None, 7, 7, 192)    258048      activation_255[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_257 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_24[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_248 (BatchN (None, 7, 7, 192)    576         conv2d_248[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_251 (BatchN (None, 7, 7, 192)    576         conv2d_251[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_256 (BatchN (None, 7, 7, 192)    576         conv2d_256[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_257 (BatchN (None, 7, 7, 192)    576         conv2d_257[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_248 (Activation)     (None, 7, 7, 192)    0           batch_normalization_248[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_251 (Activation)     (None, 7, 7, 192)    0           batch_normalization_251[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_256 (Activation)     (None, 7, 7, 192)    0           batch_normalization_256[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_257 (Activation)     (None, 7, 7, 192)    0           batch_normalization_257[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
            "                                                                 activation_251[0][0]             \n",
            "                                                                 activation_256[0][0]             \n",
            "                                                                 activation_257[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1024)         38536192    flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 1024)         0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            1025        dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "outputId": "a4c699f8-ee1a-4d1b-ba75-a7937387a221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = 'horse-or-human.zip'\n",
        "train_dir = 'training'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall(train_dir)\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = 'validation-horse-or-human.zip'\n",
        "validation_dir = 'validation'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall(validation_dir)\n",
        "zip_ref.close()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-27 02:52:51--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.188.128, 2404:6800:4008:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.188.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘horse-or-human.zip’\n",
            "\n",
            "\rhorse-or-human.zip    0%[                    ]       0  --.-KB/s               \rhorse-or-human.zip   18%[==>                 ]  26.40M   132MB/s               \rhorse-or-human.zip   51%[=========>          ]  73.68M   184MB/s               \rhorse-or-human.zip   79%[==============>     ] 113.87M   190MB/s               \rhorse-or-human.zip  100%[===================>] 142.65M   190MB/s    in 0.8s    \n",
            "\n",
            "2019-09-27 02:52:52 (190 MB/s) - ‘horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-09-27 02:52:55--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.97.128, 2404:6800:4008:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.97.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘validation-horse-or-human.zip’\n",
            "\n",
            "validation-horse-or 100%[===================>]  10.95M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-09-27 02:52:55 (77.5 MB/s) - ‘validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "outputId": "23a34fe8-e23e-45d4-88b8-7e8ebaafa859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "train_horses_dir = os.path.join(train_dir, 'horses') # Directory with our training horse pictures\n",
        "train_humans_dir = os.path.join(train_dir, 'humans') # Directory with our training humans pictures\n",
        "validation_horses_dir = os.path.join(validation_dir, 'horses') # Directory with our validation horse pictures\n",
        "validation_humans_dir = os.path.join(validation_dir, 'humans')# Directory with our validation humanas pictures\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "outputId": "ced5cd60-35da-409a-a580-337e7e79ef06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "outputId": "8a357642-dcb9-484e-d430-abc1621b448c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 100,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2,\n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 - 31s - loss: 0.0116 - acc: 0.9970 - val_loss: 1.1660 - val_acc: 0.9453\n",
            "Epoch 2/100\n",
            "100/100 - 30s - loss: 0.0173 - acc: 0.9975 - val_loss: 1.2299 - val_acc: 0.9464\n",
            "Epoch 3/100\n",
            "100/100 - 29s - loss: 0.0105 - acc: 0.9975 - val_loss: 1.2661 - val_acc: 0.9443\n",
            "Epoch 4/100\n",
            "100/100 - 29s - loss: 0.0351 - acc: 0.9975 - val_loss: 1.4314 - val_acc: 0.9352\n",
            "Epoch 5/100\n",
            "100/100 - 29s - loss: 0.0090 - acc: 0.9970 - val_loss: 1.2960 - val_acc: 0.9413\n",
            "Epoch 6/100\n",
            "100/100 - 29s - loss: 0.0504 - acc: 0.9970 - val_loss: 1.0634 - val_acc: 0.9514\n",
            "Epoch 7/100\n",
            "100/100 - 29s - loss: 0.0105 - acc: 0.9965 - val_loss: 1.2720 - val_acc: 0.9504\n",
            "Epoch 8/100\n",
            "100/100 - 28s - loss: 0.0108 - acc: 0.9975 - val_loss: 1.3949 - val_acc: 0.9393\n",
            "Epoch 9/100\n",
            "100/100 - 28s - loss: 0.0082 - acc: 0.9980 - val_loss: 1.5989 - val_acc: 0.9362\n",
            "Epoch 10/100\n",
            "100/100 - 28s - loss: 0.0091 - acc: 0.9965 - val_loss: 2.0177 - val_acc: 0.9241\n",
            "Epoch 11/100\n",
            "100/100 - 29s - loss: 0.0102 - acc: 0.9970 - val_loss: 1.7093 - val_acc: 0.9372\n",
            "Epoch 12/100\n",
            "100/100 - 28s - loss: 0.0138 - acc: 0.9970 - val_loss: 1.6263 - val_acc: 0.9403\n",
            "Epoch 13/100\n",
            "100/100 - 28s - loss: 0.0256 - acc: 0.9949 - val_loss: 1.5755 - val_acc: 0.9302\n",
            "Epoch 14/100\n",
            "100/100 - 28s - loss: 0.0166 - acc: 0.9970 - val_loss: 1.4282 - val_acc: 0.9362\n",
            "Epoch 15/100\n",
            "100/100 - 30s - loss: 0.0084 - acc: 0.9965 - val_loss: 1.0202 - val_acc: 0.9565\n",
            "Epoch 16/100\n",
            "100/100 - 30s - loss: 0.0101 - acc: 0.9965 - val_loss: 1.3920 - val_acc: 0.9433\n",
            "Epoch 17/100\n",
            "100/100 - 29s - loss: 0.0074 - acc: 0.9980 - val_loss: 1.1664 - val_acc: 0.9514\n",
            "Epoch 18/100\n",
            "100/100 - 29s - loss: 0.0075 - acc: 0.9980 - val_loss: 0.8368 - val_acc: 0.9636\n",
            "Epoch 19/100\n",
            "100/100 - 29s - loss: 0.0157 - acc: 0.9939 - val_loss: 0.7645 - val_acc: 0.9666\n",
            "Epoch 20/100\n",
            "100/100 - 28s - loss: 0.0094 - acc: 0.9970 - val_loss: 0.9689 - val_acc: 0.9595\n",
            "Epoch 21/100\n",
            "100/100 - 29s - loss: 0.0100 - acc: 0.9965 - val_loss: 1.0682 - val_acc: 0.9565\n",
            "Epoch 22/100\n",
            "100/100 - 29s - loss: 0.0092 - acc: 0.9985 - val_loss: 0.8162 - val_acc: 0.9646\n",
            "Epoch 23/100\n",
            "100/100 - 29s - loss: 0.0107 - acc: 0.9975 - val_loss: 0.9120 - val_acc: 0.9605\n",
            "Epoch 24/100\n",
            "100/100 - 29s - loss: 0.0123 - acc: 0.9970 - val_loss: 1.2774 - val_acc: 0.9464\n",
            "Epoch 25/100\n",
            "100/100 - 29s - loss: 0.0044 - acc: 0.9990 - val_loss: 1.2295 - val_acc: 0.9494\n",
            "Epoch 26/100\n",
            "100/100 - 29s - loss: 0.0207 - acc: 0.9949 - val_loss: 1.4566 - val_acc: 0.9464\n",
            "Epoch 27/100\n",
            "100/100 - 28s - loss: 0.0184 - acc: 0.9980 - val_loss: 0.9334 - val_acc: 0.9646\n",
            "Epoch 28/100\n",
            "100/100 - 30s - loss: 0.0044 - acc: 0.9980 - val_loss: 0.7992 - val_acc: 0.9656\n",
            "Epoch 29/100\n",
            "100/100 - 30s - loss: 0.0086 - acc: 0.9980 - val_loss: 1.2763 - val_acc: 0.9484\n",
            "Epoch 30/100\n",
            "100/100 - 29s - loss: 0.0119 - acc: 0.9985 - val_loss: 1.1010 - val_acc: 0.9595\n",
            "Epoch 31/100\n",
            "100/100 - 29s - loss: 0.0025 - acc: 0.9990 - val_loss: 1.0903 - val_acc: 0.9575\n",
            "Epoch 32/100\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "100/100 - 28s - loss: 7.6153e-04 - acc: 1.0000 - val_loss: 0.8689 - val_acc: 0.9686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "outputId": "573d13da-6242-4230-8e63-b189c5fe81a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}